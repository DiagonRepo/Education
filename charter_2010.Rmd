---
title: "Longitudinal study of factors influencing student academic performance in CA schools"
author: "STAT 420, Summer 2018, bching3, cindyst2, rjs8, trapido2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r eval=FALSE}
install.packages("foreign")
```

## Dataset Description

The dataset tracks the school's name, district, type (charter or not), student demographics, subject end of year test score averages, ranking in the state, class sizes, average parental education levels, and teacher credentials.

With the test scores as the response, we hope to model how charter schools will perform as compared to public schools using the other fields as predictors.

## Background

School performance as recorded by the CA Dept. of Education from 1999-2013 (https://www.cde.ca.gov/ta/ac/ap/apidatafiles.asp)

## Interest

Interest in this dataset is driven by the current administration's Education Secretary's push to increase the number of charter schools.

## Proof of Loading the Dataset into R
```{r}
library(foreign)
library(lmtest)
library(faraway)
schl2010 = read.dbf("data/api10gdb.dbf", as.is = TRUE)
schl2013 = read.dbf("data/api13gdb.dbf", as.is = TRUE)
#str(schl2010)
```
```{r}
###################
# Common Columns
###################

# Define some common columns
# Factor Columns
fac_pred = c('RTYPE', 'STYPE', 'SPED', 'SIZE', 'CHARTER', 
             "YR_RND")

# Numeric Columns
num_pred = c("ST_RANK", "SIM_RANK",
             "API10", "API13",
             "CDS",
             "AA_API", "AI_API", "AS_API", "FI_API", "HI_API", "PI_API", "WH_API", "MR_API",
             "SD_API", "EL_API", "DI_API",
             "PCT_AA", "PCT_AI", "PCT_AS", "PCT_FI", "PCT_HI","PCT_PI", "PCT_WH", "PCT_MR",
             "MEALS", "P_GATE",  "P_MIGED", "P_EL", "P_RFEP", "P_DI", "CBMOB", "DMOB", 
             "ACS_K3", "ACS_46", "ACS_CORE", 
             "PCT_RESP", "NOT_HSG", "HSG", "SOME_COL", "COL_GRAD", "GRAD_SCH", "AVG_ED",
             "PEN_2", "PEN_35", "PEN_6", "PEN_78", "PEN_911","PEN_91",
             "ENROLL", "TESTED", "SCI"
             )
```

```{r}

###################
# Helper Functions
###################

# Function to remove exact column names
remove_columns = function(dframe, columns_to_remove) {
  subset(dframe, select = !(colnames(dframe) %in% columns_to_remove))
}

# Function to remove matching column names
remove_columns_like = function(dframe, columns_to_remove) {
  tmp_df = data.frame(dframe)
  for(match in columns_to_remove) {
    tmp_df = subset(tmp_df, select = -grep(match, colnames(tmp_df), perl=TRUE, value=FALSE))
  }
  tmp_df
}

# threshold is a number from 0 to 1 to indicate how much NA you want to see
# threshold = 0.7 means show columns with 70% NAs
show_columns_with_na = function(dframe, threshold = 0.5) {
  cn = colnames(dframe)
  col_na_ratios = rep(0, length(cn))
  for(c in 1:length(cn)) {
    col_na_ratios[c] = mean(is.na(dframe[,cn[c]]))
  }
  print(cn[col_na_ratios > threshold])
  cn[col_na_ratios > threshold]
}

# Remove columns common in dataset
remove_common_columns = function(dframe) {
  # Remove all _TARG, _MET, _SIG, columns which are just metadata about whether targets were met
  # or whether columns were significant.
  dframe = remove_columns_like(dframe, c("_TARG", "_MET", "_SIG", "_NUM", "_GROW"))

  dframe$CHARTER = ifelse(is.na(dframe$CHARTER), "NC", dframe$CHARTER)

  # Remove schools designated as small for GROWTH and BASE purposes. It uses NA to mean not-small.

  # Transform STYPE column by setting NA to 'O' to indicate other
  data_2013$STYPE = as.factor(ifelse(is.na(data_2013$STYPE), "O", data_2013$STYPE))

  # Remove the names because we have the school id in the first column
  dframe = remove_columns(dframe, c("SNAME", "DNAME", "CNAME"))

  # Remove rows with AVG_ED = NA because there's not that much of them (37)
  dframe = subset(dframe, subset = !is.na(dframe$AVG_ED))

  # Remove ACS_K3, ACS_46, ACS_CORE, FULL, EMER because it's mostly if not all is NA
  dframe = remove_columns(dframe, c("ACS_K3", "ACS_46", "ACS_CORE", "FULL", "EMER"))

  dframe
}

# convert all columns listed in fac_pred to factors
conv_factor = function(dframe, columns_to_factor) {
  for(col in columns_to_factor) {
    if(col %in% colnames(dframe[0,])) {
      dframe[, col] = as.factor(dframe[, col])
    }
  }
  dframe
}

# convert all columsn to numeric
conv_numeric = function(dframe, columns_to_numeric) {
  for(col in num_pred) {
    if(col %in% colnames(dframe[0,])) {
      dframe[, col] = as.numeric(dframe[, col])
    }
  }
  dframe
}

# Function to calculate loocv_rmse
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

diagnostics = function(model, pcol = "grey", lcol = "dodgerblue", alpha = 0.05, 
                       plotit = TRUE, testit = TRUE) {
  
  if (plotit == TRUE) {
    
    # side-by-side plots (one row, two columns)
    par(mfrow = c(1, 2))
    
    # fitted versus residuals
    plot(fitted(model), resid(model), 
         col = pcol, pch = 20, cex = 1.5, 
         xlab = "Fitted", ylab = "Residuals", 
         main = "Fitted versus Residuals")
    abline(h = 0, col = lcol, lwd = 2)
    grid()
    
    # qq-plot
    qqnorm(resid(model), col = pcol, pch = 20, cex = 1.5)
    qqline(resid(model), col = lcol, lwd = 2)
    grid()
  }
  
  if (testit == TRUE) {
    # p-value and decision
    shapiro_pval = shapiro.test(resid(model))$p.value
    bptest_pval = bptest((model))$p.value
    list(shapiro_pval = shapiro_pval, bptest_pval = bptest_pval)
  }

}
```

```{r}
#############################
# Clean up data set 2010
#############################
# remove comoonly removable columns
schl2010 = remove_common_columns(schl2010)

# Remove columns unique to the dataset
# _api is related to API which we are trying to measure
schl2010 = remove_columns_like(schl2010, c("_api10", "_API09"))

# Remove schools designated as small for GROWTH and BASE purposes. It uses NA to mean not-small.
schl2010 = subset(schl2010, subset = is.na(schl2010$sm10) & is.na(schl2010$sm09), select = !(colnames(schl2010) %in% c('sm10','sm09')))

# Remove rows with MEDIAN13 or MEDIAN12 = NA
schl2010 = subset(schl2010, subset = !is.na(schl2010$MEDIAN10) | !is.na(schl2010$MEDIAN09))


# Remove schl2010 rank that are I = Invalid, B = District, or C = Special Education schl2010
#schl2010 = schl2010[!(schl2010$ST_RANK %in% c("I", "B", "C")), ]

# Remove schl2010 similar rank that are I = Invalid, B = District, or C = Special Education schl2010
#schl2010 = schl2010[!(schl2010$SIM_RANK %in% c("I", "B", "C", "O", "S")), ]

other_cols = show_columns_with_na(schl2010)
schl2010 = remove_columns(schl2010, other_cols)
schl2010 = na.omit(schl2010)
nrow(schl2010)

#############################
# Clean up data set 2013
#############################
# remove comoonly removable columns
schl2013 = remove_common_columns(schl2013)

# Remove columns unique to the dataset
# _api is related to API which we are trying to measure
schl2013 = remove_columns_like(schl2013, c("_API12", "_API13"))

# Remove schools designated as small for GROWTH and BASE purposes. It uses NA to mean not-small.
schl2013 = subset(schl2013, subset = is.na(schl2013$SM12) & is.na(schl2013$SM13), select = !(colnames(schl2013) %in% c('SM12','SM13')))

# Remove rows with MEDIAN13 or MEDIAN12 = NA
schl2013 = subset(schl2013, subset = !is.na(schl2013$MEDIAN13) | !is.na(schl2013$MEDIAN12))

other_cols = show_columns_with_na(schl2013)
schl2013 = remove_columns(schl2013, other_cols)
schl2013 = na.omit(schl2013)
nrow(schl2013)
schl2013 = na.omit(schl2013)
```


```{r}

#####################
# Convert columns to factors and numerics for 2010
####################
# convert columns to factor
schl2010 = conv_factor(schl2010, fac_pred)

# convert columns to numeric
schl2010 = conv_numeric(schl2010, num_pred)

# Randomly select 600 observations
#nrow(schl2010)
ridx = sample(nrow(schl2010), 600)
schl2010 = schl2010[ridx, ]

# split dataframe into training and test
(n = nrow(schl2010))
trn_idx = sample(nrow(schl2010), n/2)
schl2010_trn = schl2010[trn_idx, ]
schl2010_tst = schl2010[-trn_idx, ]


#####################
# Convert columns to factors and numerics for 2013
####################
# convert columns to factor
schl2013 = conv_factor(schl2013, fac_pred)

# convert columns to numeric
schl2013 = conv_numeric(schl2013, num_pred)

# Randomly select 600 observations
ridx = sample(nrow(schl2013), 600)
schl2013 = schl2013[ridx, ]

# split dataframe into training and test
(n = nrow(schl2013))
trn_idx = sample(nrow(schl2013), n/2)
schl2013_trn = schl2013[trn_idx, ]
schl2013_tst = schl2013[-trn_idx, ]
```





```{r}
#################
# 2010
#################
schl2010_fit = lm(API10  ~ PEN_78 + PEN_911 + poly(PCT_AA, 2) + poly(PCT_AI, 2) + poly(PCT_AS, 3) + poly(PCT_WH, 1) + poly(P_GATE, 1) + P_MIGED + poly(AVG_ED, 4) + poly(MEALS, 2) ,
               data = schl2010_trn)

# check assumptions
diagnostics(schl2010_fit)

# check how the model is fitting
summary(schl2010_fit)
vif(schl2010_fit) 
calc_loocv_rmse(schl2010_fit)

pred = predict(schl2010_fit, newdata = schl2010_tst)
plot(pred ~ schl2010_tst$API10, col = "dodgerblue")

#################
# 2013
#################
schl2013_fit = lm(API13  ~ PEN_78 + PEN_911 + poly(PCT_AA, 2) + poly(PCT_AI, 2) + poly(PCT_AS, 3) + poly(PCT_WH, 1) + poly(P_GATE, 1) + P_MIGED + poly(AVG_ED, 4) + MEALS ,
               data = schl2013_trn)

# check assumptions
diagnostics(schl2013_fit)

# check how the model is fitting
summary(schl2013_fit)
vif(schl2013_fit) 
calc_loocv_rmse(schl2013_fit)

pred = predict(schl2013_fit, newdata = schl2013_tst)
plot(pred ~ schl2013_tst$API13, col = "dodgerblue")
```

```{r}
# we leave out STYPE because it can be represented by student enrollment per grade (PEN_2..)
# we leaving out NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH because they can be represented by AVG_ED
# We leave out TESTEd because it's highly related with ENROLL
schl_big_mod = lm(API10 ~ #.,
                (PEN_2 + PEN_35 + PEN_6 + PEN_78 + PEN_911 +
                   CDS +
                   CHARTER + # ST_RANK + SIM_RANK + GR_TARG +
                PCT_AA + PCT_AI + PCT_AS + PCT_FI + PCT_HI + PCT_MR + PCT_WH + 
                MEALS +  # MEALS is highly correlated with AVG_ED
                  P_GATE + P_MIGED + P_RFEP + P_DI +  P_EL +
                CBMOB + DMOB + 
                PCT_RESP + 
                AVG_ED +# NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH +
                ENROLL # #TESTED +#highly correlated with ENROLL
                   #+ YR_RND #+ SCI depends on API
                ) ,
              data = schl2010_trn)

nrow(schl2010_trn)
ncol(schl2010_trn)
# Check assumptions
bptest(schl_big_mod)
shapiro.test(resid(schl_big_mod))

# Check how well the model is fitting
summary(schl_big_mod)
vif(schl_big_mod)

schl_aic = step(schl_big_mod, direction = "backward", k = log(n), trace = FALSE, maxit = 100)

# check assumptions
bptest(schl_aic)
shapiro.test(resid(schl_aic))

# check how the model is fitting
summary(schl_aic)
vif(schl_aic) 
```
### Methodology

- Split data into charter and non-charter.
- Fit models with performance as a response for both.
- Check normality assumptions.
- Responses: english score, math score, science score, exit exam score, state rank
- Factors: parental education, class size, teacher with full credentials, teacher with emergency credentials, student race, district, county
- Study should answer which factors are most relevant to performance, and the differences in those factors between charter schools and public schools
- Plot a longtitude study of how these factors affect the response change over time

```{r}

```

