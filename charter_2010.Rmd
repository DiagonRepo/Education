---
title: "Longitudinal study of factors influencing student academic performance in CA schools"
author: "STAT 420, Summer 2018, bching3, cindyst2, rjs8, trapido2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r eval=FALSE}
install.packages("foreign")
```

## Dataset Description

The dataset tracks the school's name, district, type (charter or not), student demographics, subject end of year test score averages, ranking in the state, class sizes, average parental education levels, and teacher credentials.

With the test scores as the response, we hope to model how charter schools will perform as compared to public schools using the other fields as predictors.

## Background

School performance as recorded by the CA Dept. of Education from 1999-2013 (https://www.cde.ca.gov/ta/ac/ap/apidatafiles.asp)

## Interest

Interest in this dataset is driven by the current administration's Education Secretary's push to increase the number of charter schools.

## Proof of Loading the Dataset into R
```{r}
library(foreign)
library(lmtest)
library(faraway)
data2010 = read.dbf("data/api10bdb.dbf", as.is = TRUE)
str(data2010)
```
```{r}
# Function to remove exact column names
remove_columns = function(dframe, columns_to_remove) {
  subset(dframe, select = !(colnames(dframe) %in% columns_to_remove))
}

# Function to remove matching column names
remove_columns_like = function(dframe, columns_to_remove) {
  tmp_df = data.frame(dframe)
  for(match in columns_to_remove) {
    tmp_df = subset(tmp_df, select = -grep(match, colnames(tmp_df), perl=TRUE, value=FALSE))
  }
  tmp_df
}
```

```{r}

# we only want to look at data2010s with API and Charter data filled
data2010 = data2010[which(!is.na(data2010$API10B)),]

# Remove data2010 rank that are I = Invalid, B = District, or C = Special Education data2010
data2010 = data2010[!(data2010$ST_RANK %in% c("I", "B", "C")), ]

# Remove data2010 similar rank that are I = Invalid, B = District, or C = Special Education data2010
data2010 = data2010[!(data2010$SIM_RANK %in% c("I", "B", "C", "O", "S")), ]

# Assign CHARTER == na to NC (none charter)
data2010$CHARTER = ifelse(is.na(data2010$CHARTER), "NC", data2010$CHARTER)

# Remove all _TARG, _SIG, columns which are just metadata about whether targets were met
# or whether columns were significant.
data2010 = remove_columns_like(data2010, c("_TARG", "_SIG", "_NUM", "_GT"))

# Remove ACS_K3, ACS_46, ACS_CORE, FULL, EMER because it's mostly if not all is NA
data2010 = remove_columns(data2010, c("ACS_K3", "ACS_46", "ACS_CORE", "FULL", "EMER"))

# Remove data2010/district/county name
data2010 = remove_columns_like(data2010, c("NAME"))

# we want to examine which columns is filled with NA data
# we only want to look at data that is at least half filled
sumval = rep(0, ncol(data2010))
valcold = rep(FALSE, ncol(data2010))

for (col in 1:ncol(data2010)) {
  sumval[col] = sum(!is.na(data2010[, col]) )
  valcold[col] = as.logical(sumval[col] > nrow(data2010)/2)
}

valcoln = colnames(data2010[0,])[valcold]

# we only select columns with data filled
data2010 = data2010[,valcold]
nrow(data2010)
data2010 = na.omit(data2010)
nrow(data2010)
```


```{r}

# convert predictors to factors
# not including API_TARG
fac_pred = c('RTYPE', 'STYPE', 'SPED', 'SIZE', 'CHARTER', 
             "YR_RND")

# conver predictors to numerics
# Note we purposely leave out AA_NUM, AA_SIG because they are related to PCT_AA
# could consider adding AA_API etc
num_pred = c("ST_RANK", "SIM_RANK",
             "API10B", 
             "CDS",
             "AA_API", "AI_API", "AS_API", "FI_API", "HI_API", "PI_API", "WH_API", "MR_API",
             "SD_API", "EL_API", "DI_API",
             "PCT_AA", "PCT_AI", "PCT_AS", "PCT_FI", "PCT_HI","PCT_PI", "PCT_WH", "PCT_MR",
             "MEALS", "P_GATE",  "P_MIGED", "P_EL", "P_RFEP", "P_DI", "CBMOB", "DMOB", 
             "ACS_K3", "ACS_46", "ACS_CORE", 
             "PCT_RESP", "NOT_HSG", "HSG", "SOME_COL", "COL_GRAD", "GRAD_SCH", "AVG_ED",
             "PEN_2", "PEN_35", "PEN_6", "PEN_78", "PEN_91",
             "ENROLL", "PARENT_OPT", "TESTED", "SCI"
             )

# convert all columns listed in fac_pred to factors
for(col in fac_pred) {
  if(col %in% colnames(data2010[0,])) {
    data2010[, col] = as.factor(data2010[, col])
  }
}

# convert all columns listed in num_pred to numerics
for(col in num_pred) {
  if(col %in% colnames(data2010[0,])) {
    data2010[, col] = as.numeric(data2010[, col])
  }
}

# the rest of PCT_* add up to 100%
PCT_ALL = data2010$PCT_AA + data2010$PCT_AI + data2010$PCT_AS + data2010$PCT_FI + data2010$PCT_HI + data2010$PCT_PI + data2010$PCT_WH + data2010$PCT_MR
hist(PCT_ALL)

# parents' education info adds up to 100%
ED_ALL = data2010$NOT_HSG + data2010$HSG + data2010$SOME_COL + data2010$COL_GRAD + data2010$GRAD_SCH 
hist(ED_ALL)

# percentage of data2010 enrollment adds up to PEN_ENROLL
PEN_ALL = data2010$PEN_2 + data2010$PEN_35 + data2010$PEN_6 + data2010$PEN_78 + data2010$PEN_91 
hist(PEN_ALL)

# enrolled and tested are highly correlated as well
cor(data2010$ENROLL, data2010$TESTED)

# split dataframe into training and test
# 
ridx = sample(nrow(data2010), 600)
data2010 = data2010[ridx, ]

(n = nrow(data2010))
trn_idx = sample(nrow(data2010), n/2)
data2010_trn = data2010[trn_idx, ]
data2010_tst = data2010[-trn_idx, ]
```

```{r}
# include necessary library


# define helper function
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}


# we leave out STYPE because it can be represented by student enrollment per grade (PEN_2..)
# we leaving out NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH because they can be represented by AVG_ED
# We leave out TESTEd because it's highly related with ENROLL
schl_mod = lm(API10B ~ #.,
                (PEN_2 + PEN_35 + PEN_6 + PEN_78 + PEN_91 +
                   CDS +
                   CHARTER + # ST_RANK + SIM_RANK + GR_TARG +
                PCT_AA + PCT_AI + PCT_AS + PCT_FI + PCT_HI + PCT_MR + PCT_WH + 
                MEALS +  # MEALS is highly correlated with AVG_ED
                  P_GATE + P_MIGED + P_RFEP + P_DI +  P_EL +
                CBMOB + DMOB + 
                PCT_RESP + 
                AVG_ED +# NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH +
                ENROLL + #TESTED +#highly correlated with ENROLL
                  PARENT_OPT  #+ YR_RND #+ SCI depends on API
                ) ,
              data = data2010_trn)



# Check assumptions
bptest(schl_mod)
shapiro.test(resid(schl_mod))

# Check how well the model is fitting
summary(schl_mod)
#length(coef(schl_mod)) - 1
vif(schl_mod)

```

```{r}
schl_aic = step(schl_mod, direction = "backward", k = log(n), trace = FALSE, maxit = 100)

# check assumptions
bptest(schl_aic)
shapiro.test(resid(schl_aic))

# check how the model is fitting
summary(schl_aic)
vif(schl_aic) 


```

```{r}
schl_mod2 = lm(API10B  ~ PCT_AA + PCT_AI + poly(PCT_AS, 2)  + P_GATE + P_MIGED + P_DI + P_EL + log(CBMOB) + poly(AVG_ED, 3) ,
               data = data2010_trn)


# check assumptions
bptest(schl_mod2)
shapiro.test(resid(schl_mod2))
qqnorm(resid(schl_mod2))
qqline(resid(schl_mod2))

# check how the model is fitting
summary(schl_mod2)
vif(schl_mod2) 
plot(fitted(schl_mod2) , resid(schl_mod2), col = "grey")
abline(h = 0, col = "darkorange", lwd = 3)
calc_loocv_rmse(schl_mod2)

pred = predict(schl_mod2, newdata = data2010_tst)
plot(pred ~ data2010_tst$API10B)
```

### Methodology

- Split data into charter and non-charter.
- Fit models with performance as a response for both.
- Check normality assumptions.
- Responses: english score, math score, science score, exit exam score, state rank
- Factors: parental education, class size, teacher with full credentials, teacher with emergency credentials, student race, district, county
- Study should answer which factors are most relevant to performance, and the differences in those factors between charter schools and public schools
- Plot a longtitude study of how these factors affect the response change over time

```{r}

```

