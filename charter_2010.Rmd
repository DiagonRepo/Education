---
title: "Longitudinal study of factors influencing student academic performance in CA schools"
author: "STAT 420, Summer 2018, bching3, cindyst2, rjs8, trapido2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r eval=FALSE}
install.packages("foreign")
```

## Dataset Description

The dataset tracks the school's name, district, type (charter or not), student demographics, subject end of year test score averages, ranking in the state, class sizes, average parental education levels, and teacher credentials.

With the test scores as the response, we hope to model how charter schools will perform as compared to public schools using the other fields as predictors.

## Background

School performance as recorded by the CA Dept. of Education from 1999-2013 (https://www.cde.ca.gov/ta/ac/ap/apidatafiles.asp)

## Interest

Interest in this dataset is driven by the current administration's Education Secretary's push to increase the number of charter schools.

## Proof of Loading the Dataset into R
```{r}
library(foreign)
library(lmtest)
library(faraway)
schl2010 = read.dbf("data/api10bdb.dbf", as.is = TRUE)
str(schl2010)
```
```{r}
# Function to remove exact column names
remove_columns = function(dframe, columns_to_remove) {
  subset(dframe, select = !(colnames(dframe) %in% columns_to_remove))
}

# Function to remove matching column names
remove_columns_like = function(dframe, columns_to_remove) {
  tmp_df = data.frame(dframe)
  for(match in columns_to_remove) {
    tmp_df = subset(tmp_df, select = -grep(match, colnames(tmp_df), perl=TRUE, value=FALSE))
  }
  tmp_df
}

# Function to calculate loocv_rmse
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

```

```{r}

# we only want to look at schl2010s with API and Charter data filled
schl2010 = schl2010[which(!is.na(schl2010$API10B)),]

# Remove schl2010 rank that are I = Invalid, B = District, or C = Special Education schl2010
schl2010 = schl2010[!(schl2010$ST_RANK %in% c("I", "B", "C")), ]

# Remove schl2010 similar rank that are I = Invalid, B = District, or C = Special Education schl2010
schl2010 = schl2010[!(schl2010$SIM_RANK %in% c("I", "B", "C", "O", "S")), ]

# Assign CHARTER == na to NC (none charter)
schl2010$CHARTER = ifelse(is.na(schl2010$CHARTER), "NC", schl2010$CHARTER)

# Remove all _TARG, _SIG, columns which are just metadata about whether targets were met
# or whether columns were significant.
schl2010 = remove_columns_like(schl2010, c("_TARG", "_SIG", "_NUM", "_GT"))

# Remove ACS_K3, ACS_46, ACS_CORE, FULL, EMER because it's mostly if not all is NA
schl2010 = remove_columns(schl2010, c("ACS_K3", "ACS_46", "ACS_CORE", "FULL", "EMER"))

# Remove schl2010/district/county name
schl2010 = remove_columns_like(schl2010, c("NAME"))

# we want to examine which columns is filled with NA data
# we only want to look at data that is at least half filled
sumval = rep(0, ncol(schl2010))
valcold = rep(FALSE, ncol(schl2010))

for (col in 1:ncol(schl2010)) {
  sumval[col] = sum(!is.na(schl2010[, col]) )
  valcold[col] = as.logical(sumval[col] > nrow(schl2010)/2)
}

valcoln = colnames(schl2010[0,])[valcold]

# we only select columns with data filled
schl2010 = schl2010[,valcold]
nrow(schl2010)
schl2010 = na.omit(schl2010)
nrow(schl2010)
```


```{r}

# convert predictors to factors
fac_pred = c('RTYPE', 'STYPE', 'SPED', 'SIZE', 'CHARTER', 
             "YR_RND")

# conver predictors to numerics
num_pred = c("ST_RANK", "SIM_RANK",
             "API10B", 
             "CDS",
             "AA_API", "AI_API", "AS_API", "FI_API", "HI_API", "PI_API", "WH_API", "MR_API",
             "SD_API", "EL_API", "DI_API",
             "PCT_AA", "PCT_AI", "PCT_AS", "PCT_FI", "PCT_HI","PCT_PI", "PCT_WH", "PCT_MR",
             "MEALS", "P_GATE",  "P_MIGED", "P_EL", "P_RFEP", "P_DI", "CBMOB", "DMOB", 
             "ACS_K3", "ACS_46", "ACS_CORE", 
             "PCT_RESP", "NOT_HSG", "HSG", "SOME_COL", "COL_GRAD", "GRAD_SCH", "AVG_ED",
             "PEN_2", "PEN_35", "PEN_6", "PEN_78", "PEN_91",
             "ENROLL", "PARENT_OPT", "TESTED", "SCI"
             )

# convert all columns listed in fac_pred to factors
for(col in fac_pred) {
  if(col %in% colnames(schl2010[0,])) {
    schl2010[, col] = as.factor(schl2010[, col])
  }
}

# convert all columns listed in num_pred to numerics
for(col in num_pred) {
  if(col %in% colnames(schl2010[0,])) {
    schl2010[, col] = as.numeric(schl2010[, col])
  }
}

# Randomly select 600 observations
ridx = sample(nrow(schl2010), 600)
schl2010 = schl2010[ridx, ]

# split dataframe into training and test
(n = nrow(schl2010))
trn_idx = sample(nrow(schl2010), n/2)
schl2010_trn = schl2010[trn_idx, ]
schl2010_tst = schl2010[-trn_idx, ]
```

```{r}
# we leave out STYPE because it can be represented by student enrollment per grade (PEN_2..)
# we leaving out NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH because they can be represented by AVG_ED
# We leave out TESTEd because it's highly related with ENROLL
schl_big_mod = lm(API10B ~ #.,
                (PEN_2 + PEN_35 + PEN_6 + PEN_78 + PEN_91 +
                   CDS +
                   CHARTER + # ST_RANK + SIM_RANK + GR_TARG +
                PCT_AA + PCT_AI + PCT_AS + PCT_FI + PCT_HI + PCT_MR + PCT_WH + 
                MEALS +  # MEALS is highly correlated with AVG_ED
                  P_GATE + P_MIGED + P_RFEP + P_DI +  P_EL +
                CBMOB + DMOB + 
                PCT_RESP + 
                AVG_ED +# NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH +
                ENROLL + #TESTED +#highly correlated with ENROLL
                  PARENT_OPT  #+ YR_RND #+ SCI depends on API
                ) ,
              data = schl2010_trn)

# Check assumptions
bptest(schl_big_mod)
shapiro.test(resid(schl_big_mod))

# Check how well the model is fitting
summary(schl_big_mod)
vif(schl_big_mod)

```

```{r}
schl_aic = step(schl_big_mod, direction = "backward", k = log(n), trace = FALSE, maxit = 100)

# check assumptions
bptest(schl_aic)
shapiro.test(resid(schl_aic))

# check how the model is fitting
summary(schl_aic)
vif(schl_aic) 
```

```{r}
schl_fit = lm(API10B  ~ PEN_78 + PEN_91 + poly(PCT_AA, 2) + poly(PCT_AI, 2) + poly(PCT_AS, 3) + poly(PCT_WH, 1) + poly(P_GATE, 1) + P_MIGED +  +  + poly(AVG_ED, 3) + MEALS ,
               data = schl2010_trn)

# check assumptions
bptest(schl_fit)
shapiro.test(resid(schl_fit))
qqnorm(resid(schl_fit))
qqline(resid(schl_fit))

# check how the model is fitting
summary(schl_fit)
vif(schl_fit) 
plot(fitted(schl_fit) , resid(schl_fit), col = "grey")
abline(h = 0, col = "darkorange", lwd = 3)
calc_loocv_rmse(schl_fit)

pred = predict(schl_fit, newdata = schl2010_tst)
plot(pred ~ schl2010_tst$API10B)
```

### Methodology

- Split data into charter and non-charter.
- Fit models with performance as a response for both.
- Check normality assumptions.
- Responses: english score, math score, science score, exit exam score, state rank
- Factors: parental education, class size, teacher with full credentials, teacher with emergency credentials, student race, district, county
- Study should answer which factors are most relevant to performance, and the differences in those factors between charter schools and public schools
- Plot a longtitude study of how these factors affect the response change over time

```{r}

```

