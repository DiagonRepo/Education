---
title: "Longitudinal study of factors influencing student academic performance in CA schools"
author: "STAT 420, Summer 2018, bching3, cindyst2, rjs8, trapido2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r eval=FALSE}
install.packages("foreign")
```

## Dataset Description

The dataset tracks the school's name, district, type (charter or not), student demographics, subject end of year test score averages, ranking in the state, class sizes, average parental education levels, and teacher credentials.

With the test scores as the response, we hope to model how charter schools will perform as compared to public schools using the other fields as predictors.

## Background

School performance as recorded by the CA Dept. of Education from 1999-2013 (https://www.cde.ca.gov/ta/ac/ap/apidatafiles.asp)

## Interest

Interest in this dataset is driven by the current administration's Education Secretary's push to increase the number of charter schools.

## Proof of Loading the Dataset into R
```{r}
library(foreign)
school = read.dbf("data/api10bdb.dbf", as.is = TRUE)
str(school)
```

```{r}
# we only want to look at schools with API and Charter data filled
nrow((school))  #10885
school = school[which(!is.na(school$API10B)),]
nrow(school)  #10153

# Remove school rank that are I = Invalid, B = District, or C = Special Education School
#!(school$ST_RANK %in% c("I", "B", "C"))
school = school[!(school$ST_RANK %in% c("I", "B", "C")), ]
levels(as.factor(school$ST_RANK))

# Remove school similar rank that are I = Invalid, B = District, or C = Special Education School
#!(school$ST_RANK %in% c("I", "B", "C"))
school = school[!(school$SIM_RANK %in% c("I", "B", "C", "O", "S")), ]
levels(as.factor(school$SIM_RANK))

# Assign CHARTER == na to NC (none charter)
school$CHARTER = ifelse(is.na(school$CHARTER), "NC", school$CHARTER)

# Need to investigate GR_TARG
#levels(as.factor(school$GR_TARG))

# we want to examine which columns is filled with NA data
# we only want to look at data that is at least half filled
ncol(school)
sumval = rep(0, ncol(school))
valcold = rep(FALSE, ncol(school))


for (col in 1:ncol(school)) {
  sumval[col] = sum(!is.na(school[, col]) )
  valcold[col] = as.logical(sumval[col] > nrow(school)/2)
}

valcoln = colnames(school[0,])[valcold]
valcoln

# we only select columns with data filled
school = school[,valcold]
ncol(school)
```


```{r}

# convert predictors to factors
# not including API_TARG
fac_pred = c('RTYPE', 'STYPE', 'SPED', 'SIZE', 'CHARTER', 
             "GR_TARG", "AS_GT", "YR_RND")

levels(as.factor(school$ST_RANK))

# conver predictors to numerics
# Note we purposely leave out AA_NUM, AA_SIG because they are related to PCT_AA
# could consider adding AA_API etc
num_pred = c("ST_RANK", "SIM_RANK",
             "API10B", 
             "AA_API", "AI_API", "AS_API", "FI_API", "HI_API", "PI_API", "WH_API", "MR_API",
             "SD_API", "EL_API", "DI_API",
             "PCT_AA", "PCT_AI", "PCT_AS", "PCT_FI", "PCT_HI","PCT_PI", "PCT_WH", "PCT_MR",
             "MEALS", "P_GATE",  "P_MIGED", "P_EL", "P_RFEP", "P_DI", "CBMOB", "DMOB", 
             "ACS_K3", "ACS_46", "ACS_CORE", 
             "PCT_RESP", "NOT_HSG", "HSG", "SOME_COL", "COL_GRAD", "GRAD_SCH", "AVG_ED",
             "PEN_2", "PEN_35", "PEN_6", "PEN_78", "PEN_91",
             "ENROLL", "PARENT_OPT", "TESTED", "SCI"
             )
# Only select columns we are interested in
school = subset(school, select = colnames(school[0, ]) %in% c(fac_pred, num_pred))

# Now we eliminate any observations that doesn't have all data filled
nrow(school)
ncol(school)
colnames(school[0,])
school = na.omit(school)
(n = nrow(school))  
ncol(school)


# convert all columns listed in fac_pred to factors
for(col in fac_pred) {
  if(col %in% colnames(school[0,])) {
    school[, col] = as.factor(school[, col])
  }
}

# convert all columns listed in num_pred to numerics
for(col in num_pred) {
  if(col %in% colnames(school[0,])) {
    school[, col] = as.numeric(school[, col])
  }
}

# the rest of PCT_* add up to 100%
PCT_ALL = school$PCT_AA + school$PCT_AI + school$PCT_AS + school$PCT_FI + school$PCT_HI + school$PCT_PI + school$PCT_WH + school$PCT_MR
hist(PCT_ALL)
#pct_mr_idx = which(colnames(school[0,]) == "PCT_MR")
#school = school[0, -pct_mr_idx]

# parents' education info adds up to 100%
ED_ALL = school$NOT_HSG + school$HSG + school$SOME_COL + school$COL_GRAD + school$GRAD_SCH 
hist(ED_ALL)

# percentage of school enrollment adds up to PEN_ENROLL
PEN_ALL = school$PEN_2 + school$PEN_35 + school$PEN_6 + school$PEN_78 + school$PEN_91 
hist(PEN_ALL)

# enrolled and tested are highly correlated as well
cor(school$ENROLL, school$TESTED)

# split dataframe into training and test
n = nrow(school)
trn_idx = sample(nrow(school), n/2)
school_trn = school[trn_idx, ]
school_tst = school[-trn_idx, ]
```

```{r}
# include necessary library
library(lmtest)
library(faraway)

# define helper function
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

#pairs(school_trn)
#str(school_trn)
#(unique(as.numeric(cor(school_trn[,num_pred]))))
#GR_TARG causing problem when predicting
# leaving out PCT_MR, PEN_91, and NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH because they add up to 100%
schl_mod = lm(API10B ~ #.,
                (STYPE + CHARTER + # ST_RANK + SIM_RANK + GR_TARG +
                PCT_AA + PCT_AI + PCT_AS + PCT_FI + PCT_HI + PCT_WH + #PCT_MR +
                MEALS + P_GATE + P_MIGED + P_EL + P_RFEP + P_DI +
                CBMOB + #DMOB + 
                PCT_RESP + 
                AVG_ED +# NOT_HSG + HSG + SOME_COL + COL_GRAD + GRAD_SCH +
                PEN_2 + PEN_35 + PEN_6 + PEN_78 + #PEN_91 +
                ENROLL + #TESTED + 
                  PARENT_OPT  + YR_RND #+ SCI
                ) ,#^ 2,
              data = school_trn)

# Check assumptions
bptest(schl_mod)
shapiro.test(resid(schl_mod))
qqnorm(resid(schl_mod))
qqline(resid(schl_mod))

# Check how well the model is fitting
summary(schl_mod)
#length(coef(schl_mod)) - 1
vif(schl_mod)

pred_api = predict(schl_mod, newdata = school_tst)
plot(pred_api ~ school_tst$API10B)

calc_loocv_rmse(schl_mod)
plot(fitted(schl_mod) , resid(schl_mod))

```

```{r}
schl_aic = step(schl_mod, direction = "backward", trace = FALSE, maxit = 50)

# check assumptions
bptest(schl_aic)
shapiro.test(resid(schl_aic))
qqnorm(resid(schl_aic))
qqline(resid(schl_aic))

# check how the model is fitting
summary(schl_aic)
#length(coef(schl_aic)) - 1
vif(schl_aic)
#(col = colnames(school[,which(vif(schl_aic) < 5)]))
calc_loocv_rmse(schl_mod)
plot(fitted(schl_aic) , resid(schl_aic))


```

```{r}
sum(cooks.distance(schl_aic) > 4/nrow(school_trn))
#sum(hatvalues())
schl_novif = lm(API10B ~  PCT_AA +   PCT_AI  +  PCT_AS  +  PCT_FI  +   MEALS +   P_GATE  + P_MIGED   +   P_EL +
                  P_DI   +  CBMOB + PCT_RESP  +  AVG_ED   +  PEN_2 +   PEN_35   +  PEN_6  +  PEN_78,
                select = cooks.distance(schl_aic) <= 4/nrow(school_trn),
                data = school_trn)
#schl_aic = step(schl_mod, direction = "both", trace = FALSE, maxit = 50)

# check assumptions
bptest(schl_novif)
shapiro.test(resid(schl_novif))
qqnorm(resid(schl_novif))
qqline(resid(schl_novif))

# check how the model is fitting
summary(schl_novif)
#length(coef(schl_aic)) - 1
vif(schl_novif)
calc_loocv_rmse(schl_novif)
plot(fitted(schl_novif) , resid(schl_novif))
```

### Methodology

- Split data into charter and non-charter.
- Fit models with performance as a response for both.
- Check normality assumptions.
- Responses: english score, math score, science score, exit exam score, state rank
- Factors: parental education, class size, teacher with full credentials, teacher with emergency credentials, student race, district, county
- Study should answer which factors are most relevant to performance, and the differences in those factors between charter schools and public schools
- Plot a longtitude study of how these factors affect the response change over time

```{r}

```

